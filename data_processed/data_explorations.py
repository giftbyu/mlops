# -*- coding: utf-8 -*-
"""Data_Explorations.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10e_btAnfqEBm5Isq3G8caiLa-eCsCbgR

# **1. Perkenalan Dataset**

Dataset ini berasal dari Kaggle: "Water Quality for Potability" oleh Aditya Kadiwal.
- **Sumber**: https://www.kaggle.com/datasets/adityakadiwal/water-potability
- **Tujuan**: Memprediksi kelayakan air minum berdasarkan parameter kimia
- **Fitur**: 9 parameter kualitas air
- **Target**: Potability (0 = Tidak Layak, 1 = Layak)
'''

## **1.1 Import Library yang akan digunakan**
"""

# Import library yang dibutuhkan
#!pip install kaggle
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as msno
import os
import shutil

# Preprocessing & Modeling
from sklearn.impute import KNNImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, RobustScaler

# Utilities
import joblib
import warnings
import zipfile
from IPython.display import display, Markdown
warnings.filterwarnings('ignore')

# Configure Visualization
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 12
sns.set_palette('viridis')
pd.set_option('display.max_columns', 50)
print("âœ… Libraries successfully imported")
from google.colab import drive
drive.mount('/content/drive')

"""# **2. Memuat Dataset**"""

from google.colab import files
files.upload()

target_folder = '/content/drive/MyDrive/MSML/Eksperimen_SML_septbyu/data_raw'
os.makedirs(target_folder, exist_ok=True)

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d adityakadiwal/water-potability -p {target_folder}
with zipfile.ZipFile(f'{target_folder}/water-potability.zip', 'r') as zip_ref:
   zip_ref.extractall(f'{target_folder}')


df = pd.read_csv('/content/drive/MyDrive/MSML/Eksperimen_SML_septbyu/data_raw/water_potability.csv')
df.head()

print("\nInformasi dataset:")
df.info()

"""# **3. Exploratory Data Analysis (EDA)**"""

structure_report = pd.DataFrame({
    'Feature': df.columns,
    'Data Type': df.dtypes,
    'Unique Values': df.nunique(),
    'Missing Values': df.isna().sum(),
    '% Missing': round(df.isna().mean() * 100, 2),
    'Duplicated Values': df.duplicated().sum()
})
structure_report.set_index('Feature', inplace=True)
display(structure_report)

if df.isna().sum().sum() > 0:
    # Missing values matrix
    msno.matrix(df, figsize=(10, 6), fontsize=10)
    plt.title('Missing Values Distribution', fontsize=14)
    plt.savefig('/content/drive/MyDrive/MSML/Eksperimen_SML_septbyu/data_processed/Doc_Result/missing_values_matrix.png')
    plt.show()

    # Missing values correlation
    missing_corr = df.isnull().corr()
    plt.figure(figsize=(10, 8))
    sns.heatmap(missing_corr, annot=True, cmap='coolwarm', center=0)
    plt.title('Missing Values Correlation', fontsize=14)
    plt.savefig('/content/drive/MyDrive/MSML/Eksperimen_SML_septbyu/data_processed/Doc_Result/missing_correlation.png')
    plt.show()
else:
    display(Markdown("âœ… No missing values found"))

display(Markdown("### Numerical Features Summary"))
display(df.describe().T)

print("Target Distribusi")

plt.figure(figsize=(10, 6))
ax = sns.countplot(x='Potability', data=df, palette='viridis')
plt.title('Water Potability Distribution', fontsize=16)
plt.xlabel('Potability')
plt.ylabel('Count')
total = len(df)
for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x() + p.get_width()/2., height + 10,
            f'{height/total:.1%}', ha='center')
plt.savefig('/content/drive/MyDrive/MSML/Eksperimen_SML_septbyu/data_processed/Doc_Result/target_distribution.png')
plt.show()

print("Feature Distributions")

num_cols = df.select_dtypes(include=np.number).columns.drop('Potability')
plt.figure(figsize=(16, 12))
for i, col in enumerate(num_cols):
    plt.subplot(3, 3, i+1)
    sns.histplot(df[col], kde=True, bins=30)
    plt.title(f'{col} Distribution', fontsize=12)
    plt.xlabel('')
plt.tight_layout()
plt.savefig('/content/drive/MyDrive/MSML/Eksperimen_SML_septbyu/data_processed/Doc_Result/feature_distributions.png')
plt.show()

display(Markdown("## ðŸ“Œ Deteksi Outlier"))
plt.figure(figsize=(16, 12))
for i, col in enumerate(num_cols):
    plt.subplot(3, 3, i+1)
    sns.boxplot(y=df[col])
    plt.title(f'Outlier {col}', fontsize=12)
plt.tight_layout()
plt.savefig('/content/drive/MyDrive/MSML/Eksperimen_SML_septbyu/data_processed/Doc_Result/outlier_detection.png')
plt.show()

"""# **4. Data Preprocessing**"""

print("Proses penanganan Duplikat")
initial_count = len(df)
df_clean = df.drop_duplicates()
final_count = len(df_clean)

dup_count = initial_count - final_count
print("- Initial Data Count:", initial_count)
print("- Final Data Count:", final_count)

print("Proses Penanganan Missing Values")

imputer = KNNImputer(n_neighbors=5)
df_imputed = pd.DataFrame(
    imputer.fit_transform(df_clean),
    columns=df_clean.columns
)

missing_after = df_imputed.isna().sum().sum()
print(f"Missing values setelah imputation: {missing_after}")

def iqr_capping(df, columns, factor=1.5):
    for col in columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - factor * IQR
        upper_bound = Q3 + factor * IQR

        df[col] = np.clip(df[col], lower_bound, upper_bound)
    return df

outlier_cols = ['Solids', 'Trihalomethanes', 'Conductivity']
df_imputed = iqr_capping(df_imputed, outlier_cols, factor=2.0)

print("âœ… Outlier ditangani (IQR capping) untuk:")
print(f"   - Solids (Faktor 2.0)")
print(f"   - Trihalomethanes (Faktor 2.0)")
print(f"   - Conductivity (Faktor 2.0)")

plt.figure(figsize=(12, 8))
sns.boxplot(data=df_imputed[outlier_cols])
plt.title('Distribusi Fitur Pascapenanganan Outlier', fontsize=14)
plt.savefig('/content/drive/MyDrive/MSML/Eksperimen_SML_septbyu/data_processed/Doc_Result/post_outlier_boxplot.png')
plt.show()

# Binning fitur numerik -> kategorikal
df_imputed['ph_category'] = pd.cut(
    df_imputed['ph'],
    bins=[0, 6.5, 8.5, 14],
    labels=['Asam', 'Netral', 'Basa'],
    include_lowest=True
)

df_imputed['hardness_level'] = pd.cut(
    df_imputed['Hardness'],
    bins=[0, 60, 120, 180, np.inf],
    labels=['Sangat Lunak', 'Lunak', 'Keras', 'Sangat Keras'],
    include_lowest=True
)

# Feature engineering numerik
df_imputed['mineral_saturation'] = df_imputed['Hardness'] * (10**(-df_imputed['ph']))
df_imputed['TDS_ratio'] = df_imputed['Solids'] / df_imputed['Conductivity']

print("âœ… Dibuat fitur baru:")
print("   - ph_category (Asam/Netral/Basa)")
print("   - hardness_level (Sangat Lunak/Sangat Keras)")
print("   - mineral_saturation (Hardness * 10^-pH)")
print("   - TDS_ratio (Solids/Conductivity)")

# One-Hot Encoding
from sklearn.preprocessing import OneHotEncoder
encoder = OneHotEncoder(drop='first', sparse_output=False)
encoded_features = encoder.fit_transform(df_imputed[['ph_category', 'hardness_level']])
encoded_df = pd.DataFrame(
    encoded_features,
    columns=encoder.get_feature_names_out(['ph_category', 'hardness_level'])
)

# Gabungkan dengan dataset utama
df_imputed = pd.concat([df_imputed, encoded_df], axis=1)
df_imputed = df_imputed.drop(columns=['ph_category', 'hardness_level'])

print("âœ… Fitur kategorikal di-encode:")
print(f"   Kolom baru: {list(encoded_df.columns)}")

# Pilih fitur numerik
numerical_features = [
    'Hardness', 'Solids', 'Chloramines', 'Sulfate',
    'Conductivity', 'Organic_carbon', 'Trihalomethanes',
    'Turbidity', 'mineral_saturation', 'TDS_ratio'
]

# Gunakan RobustScaler (resisten terhadap outlier)
scaler = RobustScaler()
df_imputed[numerical_features] = scaler.fit_transform(df_imputed[numerical_features])

print("âœ… Normalisasi selesai (RobustScaler)")

"""EDA VALIDASI"""

print("\n[VALIDASI] Analisis pascapreprocessing...")

# 1. Verifikasi penanganan outlier
outlier_cols = ['Solids', 'Trihalomethanes', 'Conductivity']
plt.figure(figsize=(10, 6))
sns.boxplot(data=df_imputed[outlier_cols])
plt.title('Distribusi Pascapenanganan Outlier', fontsize=14)
plt.savefig('/content/drive/MyDrive/MSML/Eksperimen_SML_septbyu/data_processed/Doc_Result/post_outlier_validation.png')
plt.show()

new_features = ['mineral_saturation', 'TDS_ratio']
_, axes = plt.subplots(1, 2, figsize=(14, 5))
sns.scatterplot(x=new_features[0], y='Potability', data=df_imputed, ax=axes[0])
sns.scatterplot(x=new_features[1], y='Potability', data=df_imputed, ax=axes[1])
plt.suptitle('Hubungan Fitur Baru dengan Target', fontsize=16)
plt.savefig('/content/drive/MyDrive/MSML/Eksperimen_SML_septbyu/data_processed/Doc_Result/new_features_validation.png')
plt.show()

plt.figure(figsize=(12, 8))
df_imputed[numerical_features].hist(bins=30, layout=(3, 4))
plt.suptitle('Distribusi Fitur Pascanormalisasi', fontsize=16)
plt.tight_layout()
plt.savefig('/content/drive/MyDrive/MSML/Eksperimen_SML_septbyu/data_processed/Doc_Result/post_scaling_distributions.png')
plt.show()

print("âœ… Validasi preprocessing selesai")

"""# **Ekspor Hasil Data Explorations**"""

processed_path = '/content/drive/MyDrive/MSML/Eksperimen_SML_septbyu/data_processed/Preproces_Waterquality.csv'

df_imputed.to_csv(processed_path, index=False)
print(f"âœ… Data bersih disimpan di: {processed_path}")

preprocessing_artifacts = {
    'imputer': imputer,
    'encoder': encoder,
    'scaler': scaler,
    'outlier_config': {
        'Solids': {'factor': 2.0},
        'Trihalomethanes': {'factor': 2.0},
        'Conductivity': {'factor': 2.0}
    }
}

joblib.dump(
    preprocessing_artifacts,
    '/content/drive/MyDrive/MSML/Eksperimen_SML_septbyu/data_processed/preprocessing_artifacts.pkl'
)
print("âœ… Metadata preprocessing disimpan")

df_pre_normalization = df_imputed.copy()

numerical_features = ['Hardness', 'Solids', 'Chloramines', 'Sulfate',
    'Conductivity', 'Organic_carbon', 'Trihalomethanes',
    'Turbidity', 'mineral_saturation', 'TDS_ratio']

df_pre_normalization[numerical_features] = scaler.inverse_transform(df_imputed[numerical_features])
df_pre_normalization.to_csv(
    '/content/drive/MyDrive/MSML/Eksperimen_SML_septbyu/data_processed/pre_normalized_data.csv',
    index=False
)
print("âœ… Versi pre-normalization disimpan")